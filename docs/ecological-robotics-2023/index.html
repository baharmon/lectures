<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8">
<title>Ecological Robotics</title>


<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

    <link rel="stylesheet" href="/lectures/reveal-js/css/reset.css">
<link rel="stylesheet" href="/lectures/reveal-js/css/reveal.css"><link rel="stylesheet" href="/lectures/reveal-hugo/themes/static-custom-theme.css" id="theme"><link rel="stylesheet" href="/lectures/highlight-js/default.min.css">
    
  </head>
  <body>
    <div class="reveal">
      <div class="slides">
  

    <section><h1 id="ecological-robotics">Ecological Robotics</h1>
<p><a href="https://baharmon.github.io/">Brendan Harmon</a> &amp;
<a href="https://hynam.org/">Hye Yeon Nam</a></p>
<img height="50px" src="../images/lsu-coad-logo.png">



<aside class="notes">
Hello. 
I am Brendan Harmon.
And I am Hye Yeon Nam.
We are presenting a novel method 
for autonomous planting.
</aside>
</section>

<section data-noprocess data-shortcode-slide
      data-background-image="../images/ecological-robotics-4.jpg"
      data-background-size="contain">
  
<h1 id="ecological-robotics-1">Ecological Robotics</h1>



<aside class="notes">
We have developed a process for 3D printing with seeds.
By extruding a seeds in mud, 
we can print complex, computational planting patterns. 
While we tested this process in the lab
with an extruder mounted on an industrial robotic arm,
we plan to deploy it in the field
using unmanned ground vehicles.
With field robots
-- like the rover pictured here --
landscapes could be 
designed computationally
and planted autonomously. 
Autonomous planting promises 
new ecological and aesthetic opportunities.
</aside>
</section><section>
<h1 id="robots-in-architecture">Robots in Architecture</h1>
<ul>
<li>Autonomous brick laying</li>
<li>Weaving tensile structures</li>
<li>Assembling timber frames</li>
<li>Constructing complex formwork</li>
<li>3D printing</li>
<li>Etc&hellip;</li>
</ul>



<aside class="notes">
Architects have been experimenting with
methods for autonomous construction.
They have developed robotic processes for
brick laying,
weaving tensile structures,
assembling timber frames,
constructing formwork,
and 3D printing materials such as
concrete, metal, and mud.
</aside>
</section><section>
<h1 id="robots-in-landscape-architecture">Robots in Landscape Architecture</h1>
<ul>
<li>Aerial Sensing</li>
<li>Autonomous Planting</li>
<li>Autonomous Mowing</li>
<li>Autonomous Earthmoving</li>
</ul>



<aside class="notes">
Landscape architects
have also been experimenting with robots.
They have developed methods for 
autonomous earth-moving, planting, and mowing. 
Through these experiments,
architects and landscape architects
have been exploring the novel
creative, material, tectonic, 
performative, and aesthetic potential 
of robots.
</aside>
</section><section>
<h1 id="pasted-based-robotic-planting">Pasted-Based Robotic Planting</h1>
<img src="../images/ecological-robotics-2.jpg" width="900">



<aside class="notes">
Our process for autonomous planting
is unique in its precision.
We use a robotic system
to extrude seeds in a paste
of clay, planting media, and water.
By extruding a paste we can 
print computationally generated patterns
with precision.
</aside>
</section><section>
<h1 id="implementation">Implementation</h1>
<img src="../images/ecological-robotics-3.jpg" width="900">



<aside class="notes">
We use a linear actuator ram
to extrude the paste.
The extruder is controlled 
by an Arduino microcontroller
and mounted on 
an industrial robotic arm.
We use the Machina library
for Grasshopper
to program the robot and the extruder.
</aside>
</section><section>
<h1 id="capabilities">Capabilities</h1>
<ul>
<li>Computational patterns</li>
<li>Microtopography</li>
<li>High precision</li>
<li>High germination rate</li>
</ul>



<aside class="notes">
Our process for autonomous planting
can print computational patterns precisely.
Because it prints a paste,
it builds microtopography.
Because the seeds 
are already in soil as a paste,
they have a high germination rate. 
</aside>
</section><section>
<h1 id="computational-planting-design">Computational Planting Design</h1>
<img src="../images/cellular-distance-noise.png" width="200">
<img src="../images/cellular-gradient-noise.png" width="200">
<img src="../images/perlin-fractal-gradient-noise.png" width="200">
<img src="../images/perlin-multifractal-noise.png" width="200">



<aside class="notes">
We can print 
algorithmically generated planting patterns.
Here are patterns 
generated from procedural noise --
from cellular,
cellular gradient, 
Perlin fractional Brownian motion,
and Perlin billow noise. 
We could also generate patterns
from cellular automata,
space filling curves,
and other algorithms.
</aside>
</section>

<section data-noprocess data-shortcode-slide
      data-background-image="../images/ecological-robotics-6.jpg">
  
<h1 id="procedural-noise-prints">Procedural Noise Prints</h1>



<aside class="notes">
Initially we tested our process in the lab,
printing in small trays.
We experimented with mixes of seeds
in different patterns.
Here, for example, is 
a print based on Perlin noise.
</aside>
</section><section>
<h1 id="living-typography">Living Typography</h1>
<p>Robotic planting as living typeface</p>



<aside class="notes">
To test the precision of our process,
we printed letterforms. 
</aside>
</section>

<section data-noprocess data-shortcode-slide
      data-background-iframe="https://player.vimeo.com/video/681194167">
  



<aside class="notes">
Here is an example.
As the robot prints,
the paste extrudes fairly smoothly.
We formulate the paste carefully,
balancing plasticity 
and growing conditions.
As the seeds germinate, 
seedlings sprout out of paste, 
their roots growing into the ground below. 
</aside>
</section><section>
<h1 id="echo">Echo</h1>
<p>Robotic planting as musical interface</p>



<aside class="notes">
With the musician Ka Hei Cheng
we transformed a 3D printed planting design
into a new musical instrument. 
</aside>
</section>

<section data-noprocess data-shortcode-slide
      data-background-iframe="https://player.vimeo.com/video/801436544">
  



<aside class="notes">
We embedded capacitive touch sensors
in the soil to transform the plants
into a living interface for
sonic performance. 
Touch the plants plays a sample
from a sound palette 
of environmental recordings.
</aside>
</section>

<section data-noprocess data-shortcode-slide
      data-background-image="../images/robotic-fieldwork-1.jpg">
  
<h1 id="field-experiment">Field Experiment</h1>



<aside class="notes">
We also conducted a field experiment.
</aside>
</section>

<section data-noprocess data-shortcode-slide
      data-background-image="../images/robotic-fieldwork-2.jpg">
  
<h1 id="field-experiment-1">Field Experiment</h1>



<aside class="notes">
Our grasses grew vigorously;
albeit too vigorously for the scale 
of planting pattern we tested.
</aside>
</section><section>
<h1 id="future-work">Future Work</h1>
<ul>
<li>Deploy on unmanned ground vehicles</li>
<li>Integrate machine vision &amp; sensors</li>
<li>Develop new methods for autonomous planting</li>
<li>Design algorithmic planting patterns</li>
<li>Conducted controlled field experiments</li>
</ul>



<aside class="notes">
To scale up, we will deploy our 
planting system on a field robot.
We will integrate sensors onto the robot
so that we can account for 
topography while printing
and monitor plant growth afterwards.
We will experiment with other 
methods for autonomous planting
such as seed hoppers.
Eventually we plan to conduct 
a controlled field experiment.
</aside>
</section>

<section data-noprocess data-shortcode-slide
      data-background-image="../images/warthog-unboxing.jpg">
  
<h1 id="field-robotics">Field Robotics</h1>
<h3 id="clearpath-warthog-ugv">Clearpath Warthog UGV</h3>



<aside class="notes">
This is our new unmanned ground vehicle.
It has real-time kinematic GNSS,
a robotic arm, and a lidar module.
We will integrate an extruder
onto the arm and start planting.
</aside>
</section><section>
<h1 id="conclusion">Conclusion</h1>
<ul>
<li>Ecological performance</li>
<li>Iterative, adaptive planting</li>
<li>Algorithmic aesthetics</li>
</ul>



<aside class="notes">
With autonomous planting,
we can design for ecological performance,
plant iteratively and adaptively,
and develop new aesthetics. 
</aside>
</section>

  


</div>
      

    </div>
<script type="text/javascript" src=/lectures/reveal-hugo/object-assign.js></script>

<a href="/lectures/reveal-js/css/print/" id="print-location" style="display: none;"></a>
<script type="text/javascript">
  var printLocationElement = document.getElementById('print-location');
  var link = document.createElement('link');
  link.rel = 'stylesheet';
  link.type = 'text/css';
  link.href = printLocationElement.href + (window.location.search.match(/print-pdf/gi) ? 'pdf.css' : 'paper.css');
  document.getElementsByTagName('head')[0].appendChild(link);
</script>

<script type="application/json" id="reveal-hugo-site-params">{"custom_theme":"reveal-hugo/themes/static-custom-theme.css"}</script>
<script type="application/json" id="reveal-hugo-page-params">null</script>

<script src="/lectures/reveal-js/js/reveal.js"></script>

<script type="text/javascript">
  
  
  function camelize(map) {
    if (map) {
      Object.keys(map).forEach(function(k) {
        newK = k.replace(/(\_\w)/g, function(m) { return m[1].toUpperCase() });
        if (newK != k) {
          map[newK] = map[k];
          delete map[k];
        }
      });
    }
    return map;
  }
  
  var revealHugoDefaults = { center: true, controls: true, history: true, progress: true, transition: "slide" };
  var revealHugoSiteParams = JSON.parse(document.getElementById('reveal-hugo-site-params').innerHTML);
  var revealHugoPageParams = JSON.parse(document.getElementById('reveal-hugo-page-params').innerHTML);
  
  var options = Object.assign({},
    camelize(revealHugoDefaults),
    camelize(revealHugoSiteParams),
    camelize(revealHugoPageParams));
  Reveal.initialize(options);
</script>


  
  
  <script type="text/javascript" src="/lectures/reveal-js/plugin/markdown/marked.js"></script>
  
  <script type="text/javascript" src="/lectures/reveal-js/plugin/markdown/markdown.js"></script>
  
  <script type="text/javascript" src="/lectures/reveal-js/plugin/highlight/highlight.js"></script>
  
  <script type="text/javascript" src="/lectures/reveal-js/plugin/zoom-js/zoom.js"></script>
  
  
  <script type="text/javascript" src="/lectures/reveal-js/plugin/notes/notes.js"></script>



    <script>
MathJax = {
  tex: {
    inlineMath: [['$', '$'], ['\\(', '\\)']]
  },
  svg: {
    fontCache: 'global'
  }
};
</script>

<script type="text/javascript" id="MathJax-script" async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js">
</script>

    
  </body>
</html>
