<!doctype html>
<html lang="en">
  <head>
    <meta charset="utf-8">
<title>Computational Ecology for Landscape Architects</title>


<meta name="apple-mobile-web-app-capable" content="yes">
<meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1.0, user-scalable=no">

    <link rel="stylesheet" href="/lectures/reveal-js/css/reset.css">
<link rel="stylesheet" href="/lectures/reveal-js/css/reveal.css"><link rel="stylesheet" href="/lectures/reveal-hugo/themes/static-custom-theme.css" id="theme"><link rel="stylesheet" href="/lectures/highlight-js/default.min.css">
    
  </head>
  <body>
    <div class="reveal">
      <div class="slides">
  

    <section><h1 id="computational-ecology">Computational Ecology</h1>
<h3 id="for-landscape-architects">for Landscape Architects</h3>
<p><a href="https://baharmon.github.io/">Brendan Harmon</a></p>
<img height="50px" src="lsu-coad-logo.png">



<aside class="notes">
Hello. 
I am Brendan Harmon,
an assistant professor of landscape architecture
at Louisiana State University.
Today I will be talking about
my recent research and teaching.
While I have expertise in the spatial sciences,
recently I have been focused on 
computational ecology and 
computational design 
- on computational methods 
for ecological research
and the creative use of computation 
in the design process.
This talk will explore several applications
of computational ecology and design including
planting and remote sensing with robots,
lidar analytics and biomass estimation, 
the preservation of heritage landscapes,
and point cloud modeling. 
</aside>
</section><section>
<h1 id="robotics">Robotics</h1>



<aside class="notes">
Since 2019, I have been exploring 
creative, ecological applications for robots
such as autonomous planting and sensing.
</aside>
</section>

<section data-noprocess data-shortcode-slide
      data-background-image="ecological-robotics-7.jpg">
  
<h1 id="ecological-robotics">Ecological Robotics</h1>



<aside class="notes">
I have been developing methods
for robotic planting 
both in the lab and the field.
</aside>
</section>

<section data-noprocess data-shortcode-slide
      data-background-image="ecological-robotics-2.jpg"
      data-background-size="contain">
  



<aside class="notes">
In the lab I developed a process 
for 3D printing with seeds.
I use a robotic system to extrude seeds 
in a paste of clay, planting media, and water.
With robotic paste-based extrusion,
seeds can be precisely planted
in computationally generated patterns.
Initially I tested this process in the lab,
printing in small trays
with mixes of seeds
in different patterns.
</aside>
</section>

<section data-noprocess data-shortcode-slide
      data-background-image="ecological-robotics-3.jpg"
      data-background-size="contain">
  



<aside class="notes">
This prototype uses Grasshopper 
to generate planting designs
and program the robot and extruder.
With this process, 
planting patterns could be generated from
procedural noise gradients,
cellular automata,
space filling curves,
AI image generation,
and other algorithms.
</aside>
</section>

<section data-noprocess data-shortcode-slide
      data-background-image="ecological-robotics-5.jpg">
  



<aside class="notes">
With robotic planting,
ecological gradients - for example -
can be computationally designe
and autonomously planted.
Here is a gradient of procedural noise.
</aside>
</section>

<section data-noprocess data-shortcode-slide
      data-background-image="ecological-robotics-6.jpg">
  



<aside class="notes">
And here is a tray of seedlings
planted in a prodecural noise gradient. 
</aside>
</section>

<section data-noprocess data-shortcode-slide
      data-background-image="ecological-robotics-4.jpg"
      data-background-size="contain">
  



<aside class="notes">
To scale up, I will deploy this
planting system on a field robot.
I plan to experiment with other 
methods for autonomous planting
such as seed hoppers.
Eventually I plan to conduct 
a controlled field experiment.
After autonomously seeding test plots,
I will use lidar to monitor growth.
With autonomous seeding at field scale,
landscapes can be 
planted iteratively and adaptively
and designed for ecological performance
with new computational aesthetics. 

</aside>
</section>

<section data-noprocess data-shortcode-slide
      data-background-image="ecological-robotics-7.jpg">
  



<aside class="notes">
This is our new unmanned ground vehicle
with real-time kinematic GNSS,
a robotic arm, and a lidar module.
I will use this field robot to plant test plots
and a demonstration garden. 
Applications for autonomous planting
include seeding meadows and prairies,
reforestation, ecological restoration,
and precision agriculture.
Imagine reforestation schemes 
that are no longer monocultural grids,
but rather in diverse communities
planted in gradients based on 
microclimatic, topographic, 
hydrological, and soil conditions.
</aside>
</section>

<section data-noprocess data-shortcode-slide
      data-background-image="echo-1.jpg">
  
<h1 id="echo">Echo</h1>



<aside class="notes">

With new media artist Hye Yeon Nam
sound artist Ka Hei Cheng, 
I used autonomous planting to highlight
the entanglement of nature and technology.
We transformed a 3D printed planting design
into a new musical instrument. 
</aside>
</section>

<section data-noprocess data-shortcode-slide
      data-background-iframe="https://player.vimeo.com/video/801436544"
      data-background-size="cover">
  



<aside class="notes">
By embedding capacitive touch sensors
in the soil,
we transformed plants
into a living interface for
sonic performance. 
Touching the seedlings plays a sample
from a sound palette 
of environmental recordings.
</aside>
</section><section>
<h1 id="computational-ecology-1">Computational Ecology</h1>



<aside class="notes">
My recent research in computational ecology
explores the use of lidar
to estimate biomass and carbon. 
</aside>
</section>

<section data-noprocess data-shortcode-slide
      data-background-image="hilltop-1.jpg">
  
<h1 id="drone-data-analytics">Drone Data Analytics</h1>



<aside class="notes">
Since 2020 I have been using drones
with lidar and multispectral sensors
to study the evolution of the meadow
established at LSU's Hilltop Arboretum.
</aside>
</section>

<section data-noprocess data-shortcode-slide
      data-background-image="hilltop-2.jpg">
  



<aside class="notes">
Here is the fixed wing drone with a multispectral sensor
that I use to capture monthly imagery of the meadow
with red, green, blue, near infrared, and rededge channels.
</aside>
</section>

<section data-noprocess data-shortcode-slide
      data-background-image="hilltop-3.jpg"
      data-background-size="contain">
  



<aside class="notes">
With regular aerial surveys 
I can map fluxes of aboveground biomass and carbon
in the meadow. 
Here, for example, is 
a 3D scatterplot of
the net annual biomass of the meadow
in its first year. 
By accounting for carbon storage in meadows and prairies,
we can demonstrate their ecoystem services
and advocate for their creation or conservation.
</aside>
</section>

<section data-noprocess data-shortcode-slide
      data-background-image="hilltop-4.jpg">
  



<aside class="notes">
Along with this research program, 
I regularly teach drone piloting, photogrammetry, and lidar
to landscape architecture students
in my computational design course. 
</aside>
</section>

<section data-noprocess data-shortcode-slide
      data-background-image="duelling-oak.jpg"
      data-background-size="contain">
  
<h1 id="atlas-of-heritage-trees">Atlas of Heritage Trees</h1>



<aside class="notes">
For another project 
- the Atlas of Heritage Trees -
I am laser scanning ancient trees
of significant historical, 
cultural, and ecological importance.
Louisiana has many large, old, 
and culturally significant specimens
of southern live oak and bald cypress. 
These trees are charismatic megaflora â€“ 
specimens that capture 
the imagination of the public 
and encourage broader support 
for biodiversity conservation.
To preserve a record of these 
irreplaceable cultural icons, 
we are compiling an Atlas of Heritage Trees.
As a digital humanities project,
this research aims to document and share
the legacy of these heritage trees.
As a work of computational ecology,
this research aims to estimate the 
biomass and carbon of large, old trees
which act as keystone ecological structures. 
</aside>
</section><section>
<img src="big-cypress-point-cloud.jpg" width="500">
<img src="big-cypress-voxels.jpg" width="400">
<img src="big-cypress-marching-cubes.jpg" width="400">
<img src="big-cypress-dendro.jpg" width="400">



<aside class="notes">
As part of this project,
I have developed a method 
for building volumetric models
from laser scanned point clouds. 
My volumetric modeling process 
can be used to calculate 
the volume of large, old trees
with extensive cavities
for biomass and carbon estimation. 
It can also be used to 3D print models 
of these specimens
for outreach, education, and exhibition.

</aside>
</section>

<section data-noprocess data-shortcode-slide
      data-background-image="big-cypress-print-xl.jpg">
  



<aside class="notes">
Here, for example, 
is a 3D print of the Big Cypress,
a 1500 year old Bald Cypress 
on Cat Island in Louisiana.
It is the largest recorded bald cypress
and the reigning national champion.
</aside>
</section><section>
<h1 id="heritage-preservation">Heritage Preservation</h1>



<aside class="notes">
My research in heritage preservation 
uses remote sensing technologies 
such as lidar
to preserve a record
of disappearing heritage landscapes.
</aside>
</section><section>
<img src="faro-focus.jpg" width="250">
<img src="matrice.jpg" width="600">



<aside class="notes">
I use drones with lidar, 
terrestrial laser scanning,
and neural radiance fields
to record the spatial structure
and phenomenological character
of heritage landscapes.
Here are some of the tools I use -
a laser scanner on a tripod 
for scanning on the ground
and a drone with real-time kinematic GNSS
and a lidar module
for scanning from above.
By combining aerial and ground based scans,
we can reconstruct complex landscapes
in minute detail.
</aside>
</section>

<section data-noprocess data-shortcode-slide
      data-background-image="rosedown-landscape.jpg">
  
<h1 id="rosedown">Rosedown</h1>



<aside class="notes">
With funding from the National Park Service,
my colleague Nick Serrano and I
scanned Rosedown Plantation
in St. Francisville, Louisiana.
Rosedown is unique for its 
extant, largely intact plantation gardens;
these gardens are important
not only for being representative of 
plantation garden design in the American South,
but also as artifacts of enslaved labor.
</aside>
</section>

<section data-noprocess data-shortcode-slide
      data-background-image="rosedown-rockery.jpg">
  



<aside class="notes">
With terrestrial laser scanning,
we captured temporal aspects of the landscape
such as the flowers in bloom on the rockery
- pictured here -
and the spanish moss swaying
on the live oak allee. 
</aside>
</section>

<section data-noprocess data-shortcode-slide
      data-background-image="rosedown-tunnel.jpg">
  



<aside class="notes">
The scan of the tunnel through the rockery,
captured details such as the pebble wash
and the moss and lichen on the bricks.
This level of immersive detail records
some of sensory experience
and phenomenological character
of the site in ways that other media cannot.
</aside>
</section>

<section data-noprocess data-shortcode-slide
      data-background-image="rosedown-staircase.jpg">
  



<aside class="notes">
The scan of the service staircase
captures how the tall steps are worn underfoot,
recording an index of the labor of the enslaved.
The point clouds for this project can be viewed
on my server xyz.cct.lsu.edu.
And the data has been archived online on Zenodo
with a free culture license.
</aside>
</section>

<section data-noprocess data-shortcode-slide
      data-background-image="petit-versailles-1.webp"
      data-background-size="contain">
  
<h1 id="le-petit-versailles">Le Petit Versailles</h1>



<aside class="notes">
Drone lidar can be use for landscape archeology.
Since lidar can penetrate forest canopy, 
it can reveal hidden landforms, traces of past landscapes.
Le Petit Versailles 
was the 19th century pleasure garden of Valcour Aimee.
Long abandoned, the ruins of the garden 
are lost beneath dense overgrowth
and a canopy of mature southern live oaks.
</aside>
</section>

<section data-noprocess data-shortcode-slide
      data-background-image="petit-versailles-2.webp"
      data-background-size="contain">
  



<aside class="notes">
To study this historic landscape,
I collected drone lidar during leaf off season this January.
Then I used a cloth simulation filter algorithm
to classify and segment bare ground,
revealing the historic waterways, mound, rockery, and paths.
This is just the beginning of this project;
I plan to experiment with other ground classification techniques
such as the multiscale curvature classification
and progressive morphological filter algorithms.
I also plan to use terrain analysis techniques 
- such as landform classification with geomorphons,
skyview factor, and principal component analysis -
to identify features in the landscape. 
In the future I plan to use these techniques 
to reveal lost histories and landscapes of the enslaved
thoughout the southern United States.
</aside>
</section>

<section data-noprocess data-shortcode-slide
      data-background-image="alford-1.jpg">
  
<h1 id="african-american-burial-grounds">African American Burial Grounds</h1>



<aside class="notes">
With an interdisciplinary team of colleagues,
I have begun a long term project
to preserve a record of the burial grounds
of enslaved African Americans 
and their descendants.
In the American South, 
These sites have long faced 
precarious conditions; 
originally built peripheral 
to antebellum plantations, 
today many occupy remnant parcels 
of isolated land. 
Climate change, 
industrial expansion, 
precarious land-tenure records, 
and dwindling populations 
of descendant communities 
threaten these cultural landscapes. 
The aim of this project 
is to develop a methodology for documenting 
the history, material culture, 
ecological character, and soundscapes 
of these neglected heritage sites. 
Here is a point cloud of Alford Cemetery
captured by a drone with a lidar module.
With drone lidar,
we can record these landscapes 
and their surroundings from above
at centimeter resolution. 
</aside>
</section>

<section data-noprocess data-shortcode-slide
      data-background-image="alford-2.jpg"
      data-background-size="contain">
  



<aside class="notes">
With terrestrial laser scanning,
we can record gravesites in immersive detail.
We are also experimenting with 
new scanning techniques such as 
neural radiance fields. 
Our plan is to use 
a segmented point cloud model 
of the cemetery as a way to 
map, curate, and explore other data.
Selecting a gravsite
within the point cloud model of the cemetery,
for example,
would reveal a curated collection
of geneological records, 
architectural drawings and measurements,
and photographs.
We have grand plans for this project
and over the next decade 
hope to record sites throughout
the southern United State and the Caribbean.
</aside>
</section><section>
<h1 id="point-clouds">Point Clouds</h1>



<aside class="notes">
I am also interested in point clouds
as a new design medium for landscape architecture,
that is both hyper-detailed, yet also abstract.
</aside>
</section>

<section data-noprocess data-shortcode-slide
      data-background-image="point-cloud-path-1.jpg"
      data-background-size="contain">
  
<h1 id="point-cloud-modeling">Point Cloud Modeling</h1>



<aside class="notes">
I have been experimenting with
point cloud modeling techniques.
Complex, detailed scenes can be composited
by classifying, segmenting, transforming, and merging point clouds. 
</aside>
</section>

<section data-noprocess data-shortcode-slide
      data-background-image="cloud-forest.jpg"
      data-background-size="contain">
  



<aside class="notes">
Features - such as these trees - 
can be classified and segmented
either manually or automatically
with algorithms and machine learning techniques.
When individual specimens have been isolated,
their biomass and carbon can be calculated.
</aside>
</section>

<section data-noprocess data-shortcode-slide
      data-background-image="gaussian-planting-1.jpg"
      data-background-size="contain">
  



<aside class="notes">
Segmented point clouds can then be transformed manually 
or algorithmically with, for example, Grasshopper
to create new designs.
Here is a simple example of 
laser scanned plants scattered
in a Gaussian distribution.
</aside>
</section><section>
<h1 id="future-research">Future Research</h1>
<ul>
<li>
<p><strong>Project:</strong> field robotics</p>
</li>
<li>
<p><strong>Paper:</strong> computational aesthetics</p>
</li>
<li>
<p><strong>Book:</strong> computational ecology</p>
</li>
<li>
<p><strong>GIS plugins:</strong> earthworks and mass flows of water and sediment</p>
</li>
<li>
<p><strong>Grasshopper plugins:</strong> lidar &amp; geospatial analytics</p>
</li>
</ul>



<aside class="notes">
My future plans include 
creative applications of field robotics,
a paper on computational aesthetics,
a book on computational ecology,
and plugin development. 
I plan to explore new ecological applications 
for field robotics such as 
mobile lidar scanning,
rapid ecological censuses,
procedural mowing, 
spot burning of weeds,
and experiment with different planting and seeding systems. 
I plan to write a paper on computational aesthetics 
that delves into contemporary philosophies such as
object oriented ontology and vital materialism.
Now that I have finished writing my book 
on computational design for landscape architects 
which is due out this May,
I plan to write a new textbook on computational ecology.
Recently I developed a GIS plugin for simulating landscape evolution.
Now I plan to develop open source GIS plugins 
for grading and earthworks
and erosion modeling.
I also plan to develop open source Grasshopper plugins
for lidar analytics and terrain analysis. 
</aside>
</section><section>
<p>Learn more at
<a href="https://baharmon.github.io/"><strong>baharmon.github.io</strong></a></p>
</section>

  


</div>
      

    </div>
<script type="text/javascript" src=/lectures/reveal-hugo/object-assign.js></script>

<a href="/lectures/reveal-js/css/print/" id="print-location" style="display: none;"></a>
<script type="text/javascript">
  var printLocationElement = document.getElementById('print-location');
  var link = document.createElement('link');
  link.rel = 'stylesheet';
  link.type = 'text/css';
  link.href = printLocationElement.href + (window.location.search.match(/print-pdf/gi) ? 'pdf.css' : 'paper.css');
  document.getElementsByTagName('head')[0].appendChild(link);
</script>

<script type="application/json" id="reveal-hugo-site-params">{"custom_theme":"reveal-hugo/themes/static-custom-theme.css"}</script>
<script type="application/json" id="reveal-hugo-page-params">null</script>

<script src="/lectures/reveal-js/js/reveal.js"></script>

<script type="text/javascript">
  
  
  function camelize(map) {
    if (map) {
      Object.keys(map).forEach(function(k) {
        newK = k.replace(/(\_\w)/g, function(m) { return m[1].toUpperCase() });
        if (newK != k) {
          map[newK] = map[k];
          delete map[k];
        }
      });
    }
    return map;
  }
  
  var revealHugoDefaults = { center: true, controls: true, history: true, progress: true, transition: "slide" };
  var revealHugoSiteParams = JSON.parse(document.getElementById('reveal-hugo-site-params').innerHTML);
  var revealHugoPageParams = JSON.parse(document.getElementById('reveal-hugo-page-params').innerHTML);
  
  var options = Object.assign({},
    camelize(revealHugoDefaults),
    camelize(revealHugoSiteParams),
    camelize(revealHugoPageParams));
  Reveal.initialize(options);
</script>


  
  
  <script type="text/javascript" src="/lectures/reveal-js/plugin/markdown/marked.js"></script>
  
  <script type="text/javascript" src="/lectures/reveal-js/plugin/markdown/markdown.js"></script>
  
  <script type="text/javascript" src="/lectures/reveal-js/plugin/highlight/highlight.js"></script>
  
  <script type="text/javascript" src="/lectures/reveal-js/plugin/zoom-js/zoom.js"></script>
  
  
  <script type="text/javascript" src="/lectures/reveal-js/plugin/notes/notes.js"></script>



    <script>
MathJax = {
  tex: {
    inlineMath: [['$', '$'], ['\\(', '\\)']]
  },
  svg: {
    fontCache: 'global'
  }
};
</script>

<script type="text/javascript" id="MathJax-script" async
  src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js">
</script>

    
  </body>
</html>
